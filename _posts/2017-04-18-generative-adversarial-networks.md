---
title:  "The Theory of Generative Adversarial Networks"
layout: multitrack
organizer_url:
abstract: "In Generative Adversarial Networks (GANs), two machines learn together about a probability distribution P by pursuing competing goals. On the one hand, the generator transforms vectors of random noise into samples that resemble the distribution P, according to the scores of the discriminator. On the other hand, the discriminator distinguishes between real samples drawn from P and fake samples synthesized by the generator. After training ends, the generator estimates an implicit generative model of the distribution P, and the discriminator estimates the energy landscape of the data.

Recent efforts have established connections between GAN training and f-divergence minimization, optimal transport, and energy-based learning. However, our theoretical understanding of GANs remains on its infancy, and many fascinating questions cry for an answer. How can we better understand the optimization dynamics of GANs? How can we evaluate the quality of a GAN? How to stabilize training of GANs? How to capture parameter uncertainty in the GAN framework, i.e. what is the analogue to the Bayesian neural network in the GAN setting?In this workshop, we will foster interesting discussions to ask ourselves these and many other questions."
categories:
- dali2017
organizers:
- given: Sebastian 
  family: Nowozin
  url: http://www.nowozin.net/sebastian/
  institute: Microsoft Research
- given: David
  family: Lopez Paz
  url: http://lopezpaz.org/
  institute: Facebook AI Research
room: Adeje
show_abstracts: false
talks:
- title: 
  speaker:
  youtube: 
  start: 
  end:
  abstract:
speakers:
- Dougal Sutherland  
- Ferenc Husz√°r 
- Emily Denton
- David Pfau 
- Olivier Bousquet 
- David Duvenaud
- Arthur Szlam
---
