---
title:  "Machine Learning and Society"
layout: workshop
organizer_url: 
categories:
- dali2016
organizers:
- firstname: Michael 
  lastname: Osborne
  url: "http://www.robots.ox.ac.uk/~mosb/"
  institute: University of Oxford
- firstname: Adrian
  lastname: Weller
  url: "http://www.csap.cam.ac.uk/network/adrian-weller/"
  institute: University of Cambridge
- firstname: Neil
  lastname: Lawrence
  url: "http://inverseprobability.com"
  institute: University of Sheffield
room: "Sala Ginepro"
show_abstracts: true
talks:
- title: "The Future of the Professions and the 'AI Fallacy'"
  speaker:  "Daniel Susskind"
  start: "9:30"
  end: "10:00"
- title: "Why Autonomous Warfare is a Bad Idea"
  speaker: "Noel Sharkey"
  start: "10:00"
  end: "10:25"
- title: "The Landscape of AI Safety/Beneficence
Research"
  speaker: "Richard Mallah"
  start: "10:25"
  end: "10:50"
- title: "How to Squash the Hype: Practical strategies for bringing the reality of research into the public conversation"
  speaker: "Katie Gorman"
  start: "10:50"
  end: "11:15"
  abstract: "Almost all of the media coverage surrounding ML and AI research shares one characteristic: hyperbole. Positive or negative, hyperbole hurts the field by raising hopes and entrenching fears. This creates unrealistic expectations for the tools being developed. We'll explore some basic strategies for how to engage with journalists and help preserve the reality of your research and the field when that story is retold." 
- title: ""
  start: "Coffee Break"
- title: "Machine Learning in the Developing World"
  speaker: "John Quinn"
  start: "11:45" 
  end: "12:10"
  abstract: "Technological and social changes across the developing world have led to a proliferation of new digital data sources, and with them opportunities for machine learning to be applied in new ways. At an individual scale, it can be useful to automate the judgement of scarce experts (e.g. by automating laboratory diagnostics or diagnosing diseases in crops); at a population scale, the information gaps that hamper effective planning can be addressed (e.g. by using satellite imagery to provide timely and detailed assessments of poverty, or using telecoms-based data on population mobility to improve epidemiological predictions). I will describe some of the opportunities and obstacles for such applications, using examples of systems developed in Uganda."
- title: ""
  speaker: "Bernhard Schoelkopf"
  start: "12:10" 
  end: "12:25"
- title: "Panel Discussion"
  speaker: "Danielle Belgrave, Joaquin Quiñonero Candela, Bernhard Schoelkopf and Neil Lawrence (to include issues of data privacy and responsibility)"
  start: "12:25" 
  end: "13:00"
- title: ""
  start: "Lunch and Afternoon Activities"
- title: "It wasn’t me, my robot did it"
  speaker: "Conrad McDonnell"
  start: "18:00"
  end: "18:25"
  abstract: "'It wasn’t me, my robot did it': Liability in current legal systems depends on foreseeability of harm and the concept of causation.  It is challenging to apply this to machine learning systems.  Even so, there is a need to attribute liability: should it be the owner, the developer, the operator, or the user?  The concept of vicarious liability. Analogy with parental liability for the act of a child.  Example of a real problem: Tay, Microsoft’s Twitter chatbot, which learned to make racist, homophobic, and anti-Semitic tweets."
  abstract2: "Realistic risk areas in the immediate future: Hacking and cyber crime by AIs is the primary risk.  Intellectual property theft.  Financial crime.  Distortion of search results or news articles. Misrepresentation (libel or slander).  Racism, hate speech, pornography and other inappropriate communication.  Suspension of utilities on which society depends: can a machine take industrial action?  Accidental or unintended harm seems more likely than intended harm.  Existing legal systems are adequate or adaptable for these risks, in general new laws and regulations are not required. There is the possibility for self-regulation by the industry."
  abstract3: "Legal personality: Legal rights and direct personal liability may be conferred effectively on a machine.  Achievable legal structures include the AI controlled company, and the self-owned AI.  Legal penalties with a meaningful impact on such systems would be based on corporate liability, and may include: financial penalties, temporary suspension of access to markets or other systems, or, in the last resort, permanent suspension or dissolution.  But, there is potential for avoidance of penalties through duplication of an operational system."
- title: ""
  speaker: "Chloe-Agathe Azencott"
  start: "18:25"
  end: "18:50"
- title: ""
  speaker: "Jonathan Price"
  start: "18:50"
  end: "19:15"
- title: "Panel Discussion"
  speaker: "Noel Sharkey, Jonathan Price, Richard Mallah, Conrad McDonnell, Adrian Weller (to include legal issues, and longer term themes)"
  start: "19:40"
  end: "20:00"
- title: "Dinner"
  start: "20:00"
speakers:
- Chloe-Agathe Azencott
- Katie Gorman
- Richard Mallah
- Conrad McDonnell
- Jonathan Price
- John Quinn
- Noel Sharkey
- Daniel Susskind
---
