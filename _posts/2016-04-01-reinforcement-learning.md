---
title:  "Reinforcement Learning"
layout: workshop
organizer_url: 
categories:
- dali2016
organizers:
- firstname: Csaba
  lastname: Szepesvari
  url: "http://www.ualberta.ca/~szepesva/"
  institute: University of Alberta
- firstname: Yasin 
  lastname: Abbasi-Yadkori
  url: "https://webdocs.cs.ualberta.ca/~abbasiya/"
  institute: Queensland University of Technology
show_abstracts: true
room: "Sala Agave"
talks:
- title: "TBA"
  speaker: "Gerhard Neumann"
  start: "09:30"
  end: "10:05"
- title: "TBA"
  speaker: "Joelle Pineau"
  start: "10:05"
  end: "10:40"
- title: "Adversarial Estimation Methods for Inverse Reinforcement Learning"
  speaker: "Brian Ziebart"
  start: "10:40"
  end: "11:15"
  abstract: "Inverse reinforcement learning attempts to rationalize demonstrated behavior by estimating a reward or cost function that makes observed decision sequences optimal. Unfortunately, this problem is ill-posed in its basic form, admitting only degenerate solutions when learning from noisy data. We present a general framework using adversarial statistical estimation methods to resolve this problem. Maximum entropy inverse optimal control is a special case linking robust causal log loss minimization to a relaxation of the Bellman equation for optimal control. We investigate other loss functions within this adversarial framework to allow better inductive alignment with performance measures and imitation learning settings of practical interest. This is joint work with Xiangli Chen, Mathew Monfort, and Peter Carr."
- title: ""
  start: "Coffee Break"
- title: "Computing Safe Policies with Inaccurate Models"
  speaker: "Marek Petrik"
  start: "11:45"
  end: "12:05"
  abstract: "A fundamental problem in sequential decision-making under uncertainty is to compute a safe policy, i.e., a policy that is guaranteed to have a better performance than a baseline strategy, given a batch of data. In this talk, I describe a model-based approach to this problem, in which the goal is to compute a safe policy, given an inaccurate model of the system with known accuracy guarantees. The inaccurate model and error bound may be constructed using the batch of data and prior knowledge about the system. I first describe a robust optimization problem whose solution is guaranteed to be safe in this setting, and study its main properties: show that it may only have randomized optimal solutions, derive a bound its performance loss, and prove that solving it is NP-hard. I then show several simple approximate solutions to this problem. Joint work with Yinlam Chow and Mohammad Ghavamzadeh"
- title: "TBA"
  speaker: "Gergely Neu"
  start: "12:05"
  end: "12:40"
- title: "Optimising the Confidence Level for Multi-Armed Bandit Algorithms"
  speaker: "Tor Lattimore"
  start: "12:40"
  end: "13:15"
  abstract: "I will present the Optimally Confident UCB algorithm for finite-armed bandits. The new algorithm is simple, efficient, empirically superb and comes with the strongest available theoretical guarantees for the subgaussian noise model. The main idea is that the confidence level should depend on the unknown risk of choosing a sub-optimal arm linearly often. Other algorithms are either too conservative (UCB) or not conservative enough (MOSS). The technical report may be found at http://arxiv.org/abs/1507.07880."
- title: ""
  start: "Lunch and Afternoon Activities"
- title: "TBA"
  speaker: "Martin Riedmiller"
  start: "18:00"
  end: "18:40"
- title: "TBA"
  speaker: "Doina Precup"
  start: "18:40"
  end: "19:20"
- title: "Discussion"
  start: "19:20"
  end: "20:00"
- title: ""
  start: "Dinner"
speakers:
- Mohammad Ghavamzadeh
- Gergely Neu
- Gerhard Neumann
- Tor Lattimore
- Marek Petrik
- Joelle Pineau
- Doina Precup
- Martin Riedmiller
- Brian Ziebart
---
